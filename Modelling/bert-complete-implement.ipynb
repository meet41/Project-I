{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "048b31c5",
   "metadata": {},
   "source": [
    "# Classical BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c0d97a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (2.3.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (1.7.1)\n",
      "Requirement already satisfied: torch in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (2.8.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (4.55.4)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (1.16.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from torch) (2025.7.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (0.34.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from requests->transformers) (2025.7.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas scikit-learn torch transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "332076f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       question_text      topic\n",
      "0  organ choos concern eye stage three point desp...    quantum\n",
      "1  certainli turn marriag consid environ school p...     climat\n",
      "2                       marriag best film dream wish  psycholog\n",
      "3  guess soon hair compani letter fund mission me...    histori\n",
      "4  know say congress view wear amount money succe...     machin\n"
     ]
    }
   ],
   "source": [
    "# step 2\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Load preprocessed CSV\n",
    "df = pd.read_csv(r\"E:\\Sem 7 Project\\Datasets\\Preprocessed Datasets\\output_part_1.csv\")\n",
    "\n",
    "# Convert list-like columns to strings if needed\n",
    "df['question_text'] = df['question_text'].apply(ast.literal_eval).apply(lambda x: ' '.join(x))\n",
    "df['topic'] = df['topic'].apply(ast.literal_eval).apply(lambda x: x[0] if len(x) > 0 else '')\n",
    "\n",
    "print(df[['question_text', 'topic']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3f1a2675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               topic  label\n",
      "6           artifici      0\n",
      "28        blockchain      1\n",
      "10            career      2\n",
      "1             climat      3\n",
      "5         cybersecur      4\n",
      "39              data      5\n",
      "17             digit      6\n",
      "9               educ      7\n",
      "22  entrepreneurship      8\n",
      "7        environment      9\n",
      "69            health     10\n",
      "3            histori     11\n",
      "4             machin     12\n",
      "31            person     13\n",
      "2          psycholog     14\n",
      "0            quantum     15\n",
      "20             robot     16\n",
      "18          sociolog     17\n",
      "8              space     18\n",
      "14               web     19\n"
     ]
    }
   ],
   "source": [
    "# step 3\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['label'] = le.fit_transform(df['topic'])\n",
    "num_labels = len(le.classes_)\n",
    "print(df[['topic', 'label']].drop_duplicates().sort_values('label'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8877ad33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               topic  label\n",
      "6           artifici      0\n",
      "28        blockchain      1\n",
      "10            career      2\n",
      "1             climat      3\n",
      "5         cybersecur      4\n",
      "39              data      5\n",
      "17             digit      6\n",
      "9               educ      7\n",
      "22  entrepreneurship      8\n",
      "7        environment      9\n",
      "69            health     10\n",
      "3            histori     11\n",
      "4             machin     12\n",
      "31            person     13\n",
      "2          psycholog     14\n",
      "0            quantum     15\n",
      "20             robot     16\n",
      "18          sociolog     17\n",
      "8              space     18\n",
      "14               web     19\n"
     ]
    }
   ],
   "source": [
    "# step 4\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['label'] = le.fit_transform(df['topic'])\n",
    "num_labels = len(le.classes_)\n",
    "print(df[['topic', 'label']].drop_duplicates().sort_values('label'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8621f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Meet\\AppData\\Roaming\\Python\\Python313\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_texts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtokenize\u001b[39m(texts, max_length=\u001b[32m64\u001b[39m):\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer(\n\u001b[32m      8\u001b[39m         \u001b[38;5;28mlist\u001b[39m(texts),\n\u001b[32m      9\u001b[39m         padding=\u001b[33m'\u001b[39m\u001b[33mmax_length\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m         return_tensors=\u001b[33m'\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     13\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m train_encodings = tokenize(\u001b[43mtrain_texts\u001b[49m)\n\u001b[32m     16\u001b[39m val_encodings = tokenize(val_texts)\n",
      "\u001b[31mNameError\u001b[39m: name 'train_texts' is not defined"
     ]
    }
   ],
   "source": [
    "# step 5\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def tokenize(texts, max_length=64):\n",
    "    return tokenizer(\n",
    "        list(texts),\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "train_encodings = tokenize(train_texts)\n",
    "val_encodings = tokenize(val_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "013b8741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 6\n",
    "import torch\n",
    "\n",
    "class BertDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels.iloc[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = BertDataset(train_encodings, train_labels)\n",
    "val_dataset = BertDataset(val_encodings, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f412bdf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 20:50, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.043700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.076600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.974200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.953300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.889000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.770500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2.706800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.600500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2.483800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.531600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2.388100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2.234100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>2.132000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2.100700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.914500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.952100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.860800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.789800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.769000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.687200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=200, training_loss=2.3929232215881346, metrics={'train_runtime': 1262.5559, 'train_samples_per_second': 1.267, 'train_steps_per_second': 0.158, 'total_flos': 52630715596800.0, 'train_loss': 2.3929232215881346, 'epoch': 10.0})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 7\n",
    "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_labels)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./N-Results/classical_bert',\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "41ed2377",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Meet\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 21:05, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.688900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.557200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.391800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.385700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.161800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.043800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.837600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.772000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.623500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.634200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.511100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.457600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.403700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.389500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.289100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.336900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.260900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.277100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.251900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.227500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train time\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "trainer.train()\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "31fd878d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Meet\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.05\n",
      "Precision: 0.03571428571428571\n",
      "Recall: 0.05\n",
      "F1-Score: 0.04\n",
      "\n",
      "Classification Report:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "        artifici       0.33      0.33      0.33         3\n",
      "      blockchain       0.00      0.00      0.00         3\n",
      "          career       0.00      0.00      0.00         2\n",
      "          climat       0.00      0.00      0.00         2\n",
      "      cybersecur       0.00      0.00      0.00         2\n",
      "            data       0.00      0.00      0.00         3\n",
      "           digit       0.00      0.00      0.00         3\n",
      "            educ       0.00      0.00      0.00         1\n",
      "entrepreneurship       0.00      0.00      0.00         2\n",
      "     environment       0.00      0.00      0.00         2\n",
      "          health       0.00      0.00      0.00         1\n",
      "         histori       0.00      0.00      0.00         1\n",
      "          machin       0.00      0.00      0.00         1\n",
      "          person       0.14      0.33      0.20         3\n",
      "       psycholog       0.00      0.00      0.00         2\n",
      "         quantum       0.00      0.00      0.00         1\n",
      "           robot       0.00      0.00      0.00         3\n",
      "        sociolog       0.00      0.00      0.00         2\n",
      "           space       0.00      0.00      0.00         2\n",
      "             web       0.00      0.00      0.00         1\n",
      "\n",
      "        accuracy                           0.05        40\n",
      "       macro avg       0.02      0.03      0.03        40\n",
      "    weighted avg       0.04      0.05      0.04        40\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Meet\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\Meet\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\Meet\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# step 8\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "\n",
    "# Get predictions\n",
    "preds = trainer.predict(val_dataset)\n",
    "y_true = val_labels.values\n",
    "y_pred = preds.predictions.argmax(axis=1)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b2a27657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted topic: histori\n"
     ]
    }
   ],
   "source": [
    "# step 9\n",
    "# test_texts = [\"marriag best film dream wish\"]\n",
    "test_texts = ['guess soon hair compani letter fund mission medic import tradit everyon']\n",
    "test_encodings = tokenize(test_texts)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(**{k: v for k, v in test_encodings.items()})\n",
    "    probs = torch.softmax(outputs.logits, dim=1)\n",
    "    pred_label = probs.argmax(dim=1).item()\n",
    "    pred_topic = le.inverse_transform([pred_label])[0]\n",
    "    print(\"Predicted topic:\", pred_topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340d2859",
   "metadata": {},
   "source": [
    "# DistillBert Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6550440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (2.3.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (1.7.1)\n",
      "Requirement already satisfied: torch in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (2.8.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (4.55.4)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (1.16.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from torch) (2025.7.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (0.34.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from requests->transformers) (2025.7.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas scikit-learn torch transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c79b4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       question_text      topic\n",
      "0  organ choos concern eye stage three point desp...    quantum\n",
      "1  certainli turn marriag consid environ school p...     climat\n",
      "2                       marriag best film dream wish  psycholog\n",
      "3  guess soon hair compani letter fund mission me...    histori\n",
      "4  know say congress view wear amount money succe...     machin\n"
     ]
    }
   ],
   "source": [
    "# step 2 : load & preprocess data\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Load preprocessed CSV\n",
    "df = pd.read_csv(r\"E:\\\\Sem 7 Project\\\\Datasets\\\\Preprocessed Datasets\\\\output_part_1.csv\")\n",
    "\n",
    "# Convert list-like columns to strings if needed\n",
    "df['question_text'] = df['question_text'].apply(ast.literal_eval).apply(lambda x: ' '.join(x))\n",
    "df['topic'] = df['topic'].apply(ast.literal_eval).apply(lambda x: x[0] if len(x) > 0 else '')\n",
    "\n",
    "print(df[['question_text', 'topic']].head())\n",
    "# Expected: First 5 rows of question_text and topic columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ff6ba18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               topic  label\n",
      "6           artifici      0\n",
      "28        blockchain      1\n",
      "10            career      2\n",
      "1             climat      3\n",
      "5         cybersecur      4\n",
      "39              data      5\n",
      "17             digit      6\n",
      "9               educ      7\n",
      "22  entrepreneurship      8\n",
      "7        environment      9\n",
      "69            health     10\n",
      "3            histori     11\n",
      "4             machin     12\n",
      "31            person     13\n",
      "2          psycholog     14\n",
      "0            quantum     15\n",
      "20             robot     16\n",
      "18          sociolog     17\n",
      "8              space     18\n",
      "14               web     19\n"
     ]
    }
   ],
   "source": [
    "# step 3\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['label'] = le.fit_transform(df['topic'])\n",
    "num_labels = len(le.classes_)\n",
    "print(df[['topic', 'label']].drop_duplicates().sort_values('label'))\n",
    "# Expected: Unique topics and their encoded labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb6f2f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160 40\n"
     ]
    }
   ],
   "source": [
    "# step 4 - train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df['question_text'], df['label'], test_size=0.2, random_state=42, stratify=df['label']\n",
    ")\n",
    "print(len(train_texts), len(val_texts))\n",
    "# Expected: Number of training and validation samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de278950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeysView({'input_ids': tensor([[  101, 17935,  3775,  ...,     0,     0,     0],\n",
      "        [  101,  3813,  2529,  ...,     0,     0,     0],\n",
      "        [  101,  2025,  2594,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  2530,  3519,  ...,     0,     0,     0],\n",
      "        [  101,  2345,  5770,  ...,     0,     0,     0],\n",
      "        [  101,  3693,  3095,  ...,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])})\n"
     ]
    }
   ],
   "source": [
    "# step 5\n",
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "def tokenize(texts, max_length=128):\n",
    "    return tokenizer(\n",
    "        list(texts),\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "train_encodings = tokenize(train_texts)\n",
    "val_encodings = tokenize(val_texts)\n",
    "print(train_encodings.keys())\n",
    "# Expected: dict_keys(['input_ids', 'attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19501586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160 40\n"
     ]
    }
   ],
   "source": [
    "# step 6 - dataset class preparation\n",
    "import torch\n",
    "\n",
    "class BertDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels.iloc[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = BertDataset(train_encodings, train_labels)\n",
    "val_dataset = BertDataset(val_encodings, val_labels)\n",
    "print(len(train_dataset), len(val_dataset))\n",
    "# Expected: Number of samples in train and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6141b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='240' max='240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [240/240 49:53, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.015500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.018600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.950400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.911000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.815500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.788500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2.623300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.547700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2.326300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.326200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2.115100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2.030600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.853600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.756700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.572100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.638300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.405000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.399000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.307200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.247300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.181100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.126200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.161800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.068900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time (seconds): 3011.14\n",
      "Training Time (minutes): 50.19\n"
     ]
    }
   ],
   "source": [
    "# step 7 - model training\n",
    "from transformers import DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "import time\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=num_labels)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./N-Results/results_distilbert',\n",
    "    num_train_epochs=12,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    logging_dir='./N-Results/logs_distilbert',\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "trainer.train()\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "print(f\"Training Time (seconds): {training_time:.2f}\")\n",
    "print(f\"Training Time (minutes): {training_time/60:.2f}\")\n",
    "# Expected: Training time in seconds and minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e9da091",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Meet\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.025\n",
      "Precision: 0.009375\n",
      "Recall: 0.025\n",
      "F1-Score: 0.013636363636363636\n",
      "Confusion Matrix:\n",
      "[[0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0]\n",
      " [0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0]\n",
      " [0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "\n",
      "Classification Report:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "        artifici       0.00      0.00      0.00         3\n",
      "      blockchain       0.00      0.00      0.00         3\n",
      "          career       0.00      0.00      0.00         2\n",
      "          climat       0.00      0.00      0.00         2\n",
      "      cybersecur       0.00      0.00      0.00         2\n",
      "            data       0.00      0.00      0.00         3\n",
      "           digit       0.00      0.00      0.00         3\n",
      "            educ       0.00      0.00      0.00         1\n",
      "entrepreneurship       0.00      0.00      0.00         2\n",
      "     environment       0.00      0.00      0.00         2\n",
      "          health       0.00      0.00      0.00         1\n",
      "         histori       0.00      0.00      0.00         1\n",
      "          machin       0.00      0.00      0.00         1\n",
      "          person       0.12      0.33      0.18         3\n",
      "       psycholog       0.00      0.00      0.00         2\n",
      "         quantum       0.00      0.00      0.00         1\n",
      "           robot       0.00      0.00      0.00         3\n",
      "        sociolog       0.00      0.00      0.00         2\n",
      "           space       0.00      0.00      0.00         2\n",
      "             web       0.00      0.00      0.00         1\n",
      "\n",
      "        accuracy                           0.03        40\n",
      "       macro avg       0.01      0.02      0.01        40\n",
      "    weighted avg       0.01      0.03      0.01        40\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Meet\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\Meet\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\Meet\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# step 8 - model evaluation\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "\n",
    "# Get predictions\n",
    "preds = trainer.predict(val_dataset)\n",
    "y_true = val_labels.values\n",
    "y_pred = preds.predictions.argmax(axis=1)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "report = classification_report(y_true, y_pred, target_names=le.classes_)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(\"\\nClassification Report:\\n\", report)\n",
    "# Expected: ML metrics and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3aa80a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted topic: machin\n"
     ]
    }
   ],
   "source": [
    "# step 9\n",
    "test_texts = [\"marriag best film dream wish\"]\n",
    "test_encodings = tokenize(test_texts)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(**{k: v for k, v in test_encodings.items()})\n",
    "    probs = torch.softmax(outputs.logits, dim=1)\n",
    "    pred_label = probs.argmax(dim=1).item()\n",
    "    pred_topic = le.inverse_transform([pred_label])[0]\n",
    "    print(\"Predicted topic:\", pred_topic)\n",
    "# Expected: Predicted topic for the input text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048d7919",
   "metadata": {},
   "source": [
    "# Roberta Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4553b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (2.3.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (1.7.1)\n",
      "Requirement already satisfied: torch in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (2.8.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (4.55.4)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (1.16.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from torch) (2025.7.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (0.34.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from requests->transformers) (2025.7.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas scikit-learn torch transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b1225ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       question_text      topic\n",
      "0  organ choos concern eye stage three point desp...    quantum\n",
      "1  certainli turn marriag consid environ school p...     climat\n",
      "2                       marriag best film dream wish  psycholog\n",
      "3  guess soon hair compani letter fund mission me...    histori\n",
      "4  know say congress view wear amount money succe...     machin\n"
     ]
    }
   ],
   "source": [
    "# step 2\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Load preprocessed CSV\n",
    "df = pd.read_csv(r\"E:\\\\Sem 7 Project\\\\Datasets\\\\Preprocessed Datasets\\\\output_part_1.csv\")\n",
    "\n",
    "# Convert list-like columns to strings if needed\n",
    "df['question_text'] = df['question_text'].apply(ast.literal_eval).apply(lambda x: ' '.join(x))\n",
    "df['topic'] = df['topic'].apply(ast.literal_eval).apply(lambda x: x[0] if len(x) > 0 else '')\n",
    "\n",
    "print(df[['question_text', 'topic']].head())\n",
    "# Expected: First 5 rows of question_text and topic columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "969194fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               topic  label\n",
      "6           artifici      0\n",
      "28        blockchain      1\n",
      "10            career      2\n",
      "1             climat      3\n",
      "5         cybersecur      4\n",
      "39              data      5\n",
      "17             digit      6\n",
      "9               educ      7\n",
      "22  entrepreneurship      8\n",
      "7        environment      9\n",
      "69            health     10\n",
      "3            histori     11\n",
      "4             machin     12\n",
      "31            person     13\n",
      "2          psycholog     14\n",
      "0            quantum     15\n",
      "20             robot     16\n",
      "18          sociolog     17\n",
      "8              space     18\n",
      "14               web     19\n"
     ]
    }
   ],
   "source": [
    "# step 3\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['label'] = le.fit_transform(df['topic'])\n",
    "num_labels = len(le.classes_)\n",
    "print(df[['topic', 'label']].drop_duplicates().sort_values('label'))\n",
    "# Expected: Unique topics and their encoded labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f10cd13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160 40\n"
     ]
    }
   ],
   "source": [
    "# step 4 - train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df['question_text'], df['label'], test_size=0.2, random_state=42, stratify=df['label']\n",
    ")\n",
    "print(len(train_texts), len(val_texts))\n",
    "# Expected: Number of training and validation samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a735bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeysView({'input_ids': tensor([[    0, 28878,   118,  ...,     1,     1,     1],\n",
      "        [    0,   506,  9856,  ...,     1,     1,     1],\n",
      "        [    0,  3654,   636,  ...,     1,     1,     1],\n",
      "        ...,\n",
      "        [    0, 16507, 12442,  ...,     1,     1,     1],\n",
      "        [    0,  6156,  1796,  ...,     1,     1,     1],\n",
      "        [    0, 26960,   813,  ...,     1,     1,     1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])})\n"
     ]
    }
   ],
   "source": [
    "# step 5\n",
    "from transformers import RobertaTokenizer\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "def tokenize(texts, max_length=128):\n",
    "    return tokenizer(\n",
    "        list(texts),\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "train_encodings = tokenize(train_texts)\n",
    "val_encodings = tokenize(val_texts)\n",
    "print(train_encodings.keys())\n",
    "# Expected: dict_keys(['input_ids', 'attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0369405b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160 40\n"
     ]
    }
   ],
   "source": [
    "# step 6\n",
    "import torch\n",
    "\n",
    "class BertDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels.iloc[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = BertDataset(train_encodings, train_labels)\n",
    "val_dataset = BertDataset(val_encodings, val_labels)\n",
    "print(len(train_dataset), len(val_dataset))\n",
    "# Expected: Number of samples in train and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a0add0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\Meet\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 1:04:34, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.020100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.015300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.994000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.003500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.978900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.003600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2.973500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.990100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2.963800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.001100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2.940800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2.948100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>2.844700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2.881800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.676700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>2.740900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>2.552200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>2.467700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>2.409700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.338500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time (seconds): 3901.69\n",
      "Training Time (minutes): 65.03\n"
     ]
    }
   ],
   "source": [
    "# step 7\n",
    "from transformers import RobertaForSequenceClassification, Trainer, TrainingArguments\n",
    "import time\n",
    "\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=num_labels)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./N-Results/results_roberta',\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    logging_dir='./N-Results/logs_roberta',\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "trainer.train()\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "print(f\"Training Time (seconds): {training_time:.2f}\")\n",
    "print(f\"Training Time (minutes): {training_time/60:.2f}\")\n",
    "# Expected: Training time in seconds and minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd8221ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Meet\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1\n",
      "Precision: 0.05863095238095238\n",
      "Recall: 0.1\n",
      "F1-Score: 0.06999999999999999\n",
      "Confusion Matrix:\n",
      "[[0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [2 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [2 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 2 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "\n",
      "Classification Report:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "        artifici       0.00      0.00      0.00         3\n",
      "      blockchain       0.00      0.00      0.00         3\n",
      "          career       0.00      0.00      0.00         2\n",
      "          climat       0.00      0.00      0.00         2\n",
      "      cybersecur       0.50      0.50      0.50         2\n",
      "            data       0.00      0.00      0.00         3\n",
      "           digit       0.08      0.33      0.13         3\n",
      "            educ       0.00      0.00      0.00         1\n",
      "entrepreneurship       0.00      0.00      0.00         2\n",
      "     environment       0.00      0.00      0.00         2\n",
      "          health       0.00      0.00      0.00         1\n",
      "         histori       0.00      0.00      0.00         1\n",
      "          machin       0.00      0.00      0.00         1\n",
      "          person       0.14      0.33      0.20         3\n",
      "       psycholog       0.00      0.00      0.00         2\n",
      "         quantum       0.00      0.00      0.00         1\n",
      "           robot       0.00      0.00      0.00         3\n",
      "        sociolog       0.33      0.50      0.40         2\n",
      "           space       0.00      0.00      0.00         2\n",
      "             web       0.00      0.00      0.00         1\n",
      "\n",
      "        accuracy                           0.10        40\n",
      "       macro avg       0.05      0.08      0.06        40\n",
      "    weighted avg       0.06      0.10      0.07        40\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Meet\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\Meet\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\Meet\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# step 8\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "\n",
    "# Get predictions\n",
    "preds = trainer.predict(val_dataset)\n",
    "y_true = val_labels.values\n",
    "y_pred = preds.predictions.argmax(axis=1)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "report = classification_report(y_true, y_pred, target_names=le.classes_)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(\"\\nClassification Report:\\n\", report)\n",
    "# Expected: ML metrics and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "91850ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted topic: digit\n"
     ]
    }
   ],
   "source": [
    "# step 9\n",
    "\n",
    "# test_texts = [\"marriag best film dream wish\"]\n",
    "# test_encodings = tokenize(test_texts)\n",
    "test_texts = ['guess soon hair compani letter fund mission medic import tradit everyon']\n",
    "test_encodings = tokenize(test_texts)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(**{k: v for k, v in test_encodings.items()})\n",
    "    probs = torch.softmax(outputs.logits, dim=1)\n",
    "    pred_label = probs.argmax(dim=1).item()\n",
    "    pred_topic = le.inverse_transform([pred_label])[0]\n",
    "    print(\"Predicted topic:\", pred_topic)\n",
    "# Expected: Predicted topic for the input text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7eeb3b2",
   "metadata": {},
   "source": [
    "# Albert Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42665889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (2.3.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (1.7.1)\n",
      "Requirement already satisfied: torch in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (2.8.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (4.56.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (1.16.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from torch) (2025.7.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (0.34.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (0.22.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from requests->transformers) (2025.7.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas scikit-learn torch transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7a9143c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       question_text      topic\n",
      "0  organ choos concern eye stage three point desp...    quantum\n",
      "1  certainli turn marriag consid environ school p...     climat\n",
      "2                       marriag best film dream wish  psycholog\n",
      "3  guess soon hair compani letter fund mission me...    histori\n",
      "4  know say congress view wear amount money succe...     machin\n"
     ]
    }
   ],
   "source": [
    "# step 2\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Load preprocessed CSV\n",
    "df = pd.read_csv(r\"E:\\\\Sem 7 Project\\\\Datasets\\\\Preprocessed Datasets\\\\output_part_1.csv\")\n",
    "\n",
    "# Convert list-like columns to strings if needed\n",
    "df['question_text'] = df['question_text'].apply(ast.literal_eval).apply(lambda x: ' '.join(x))\n",
    "df['topic'] = df['topic'].apply(ast.literal_eval).apply(lambda x: x[0] if len(x) > 0 else '')\n",
    "\n",
    "print(df[['question_text', 'topic']].head())\n",
    "# Expected: First 5 rows of question_text and topic columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d05bec48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               topic  label\n",
      "6           artifici      0\n",
      "28        blockchain      1\n",
      "10            career      2\n",
      "1             climat      3\n",
      "5         cybersecur      4\n",
      "39              data      5\n",
      "17             digit      6\n",
      "9               educ      7\n",
      "22  entrepreneurship      8\n",
      "7        environment      9\n",
      "69            health     10\n",
      "3            histori     11\n",
      "4             machin     12\n",
      "31            person     13\n",
      "2          psycholog     14\n",
      "0            quantum     15\n",
      "20             robot     16\n",
      "18          sociolog     17\n",
      "8              space     18\n",
      "14               web     19\n"
     ]
    }
   ],
   "source": [
    "# step 3\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['label'] = le.fit_transform(df['topic'])\n",
    "num_labels = len(le.classes_)\n",
    "print(df[['topic', 'label']].drop_duplicates().sort_values('label'))\n",
    "# Expected: Unique topics and their encoded labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9f3ea08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160 40\n"
     ]
    }
   ],
   "source": [
    "# step 4\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df['question_text'], df['label'], test_size=0.2, random_state=42, stratify=df['label']\n",
    ")\n",
    "print(len(train_texts), len(val_texts))\n",
    "# Expected: Number of training and validation samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0db45b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Meet\\AppData\\Roaming\\Python\\Python313\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeysView({'input_ids': tensor([[   2, 7821, 1388,  ...,    0,    0,    0],\n",
      "        [   2, 1904,  585,  ...,    0,    0,    0],\n",
      "        [   2,   52,  596,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   2,  650, 1656,  ...,    0,    0,    0],\n",
      "        [   2,  426, 4234,  ...,    0,    0,    0],\n",
      "        [   2, 1865, 1138,  ...,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])})\n"
     ]
    }
   ],
   "source": [
    "# step 5\n",
    "from transformers import AlbertTokenizer\n",
    "\n",
    "tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')\n",
    "\n",
    "def tokenize(texts, max_length=128):\n",
    "    return tokenizer(\n",
    "        list(texts),\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "train_encodings = tokenize(train_texts)\n",
    "val_encodings = tokenize(val_texts)\n",
    "print(train_encodings.keys())\n",
    "# Expected: dict_keys(['input_ids', 'attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fab5121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160 40\n"
     ]
    }
   ],
   "source": [
    "# step 6\n",
    "import torch\n",
    "\n",
    "class BertDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels.iloc[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = BertDataset(train_encodings, train_labels)\n",
    "val_dataset = BertDataset(val_encodings, val_labels)\n",
    "print(len(train_dataset), len(val_dataset))\n",
    "# Expected: Number of samples in train and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28f75ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\Meet\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 40:10, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.104700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.118600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3.086500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.055000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.028900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.080800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>3.039500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.051200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3.007500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.047900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2.959900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2.976800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>2.922200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2.938900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.763500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>2.791400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>2.589500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>2.615300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>2.537600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.428200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time (seconds): 2422.72\n",
      "Training Time (minutes): 40.38\n"
     ]
    }
   ],
   "source": [
    "# step 7\n",
    "from transformers import AlbertForSequenceClassification, Trainer, TrainingArguments\n",
    "import time\n",
    "\n",
    "model = AlbertForSequenceClassification.from_pretrained('albert-base-v2', num_labels=num_labels)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./N-Results/results_albert',\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    logging_dir='./N-Results/logs_albert',\n",
    "    logging_steps=10,\n",
    "    # evaluation_strategy='epoch',\n",
    "    # save_strategy='epoch',\n",
    "    # load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "trainer.train()\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "print(f\"Training Time (seconds): {training_time:.2f}\")\n",
    "print(f\"Training Time (minutes): {training_time/60:.2f}\")\n",
    "# Expected: Training time in seconds and minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac6fc3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Meet\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.025\n",
      "Precision: 0.01\n",
      "Recall: 0.025\n",
      "F1-Score: 0.014285714285714285\n",
      "Confusion Matrix:\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 2 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 1 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 2 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]]\n",
      "\n",
      "Classification Report:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "        artifici       0.00      0.00      0.00         3\n",
      "      blockchain       0.00      0.00      0.00         3\n",
      "          career       0.00      0.00      0.00         2\n",
      "          climat       0.00      0.00      0.00         2\n",
      "      cybersecur       0.00      0.00      0.00         2\n",
      "            data       0.00      0.00      0.00         3\n",
      "           digit       0.00      0.00      0.00         3\n",
      "            educ       0.00      0.00      0.00         1\n",
      "entrepreneurship       0.00      0.00      0.00         2\n",
      "     environment       0.00      0.00      0.00         2\n",
      "          health       0.00      0.00      0.00         1\n",
      "         histori       0.00      0.00      0.00         1\n",
      "          machin       0.00      0.00      0.00         1\n",
      "          person       0.00      0.00      0.00         3\n",
      "       psycholog       0.00      0.00      0.00         2\n",
      "         quantum       0.00      0.00      0.00         1\n",
      "           robot       0.00      0.00      0.00         3\n",
      "        sociolog       0.20      0.50      0.29         2\n",
      "           space       0.00      0.00      0.00         2\n",
      "             web       0.00      0.00      0.00         1\n",
      "\n",
      "        accuracy                           0.03        40\n",
      "       macro avg       0.01      0.03      0.01        40\n",
      "    weighted avg       0.01      0.03      0.01        40\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Meet\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\Meet\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\Meet\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# step 8\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "\n",
    "# Get predictions\n",
    "preds = trainer.predict(val_dataset)\n",
    "y_true = val_labels.values\n",
    "y_pred = preds.predictions.argmax(axis=1)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "report = classification_report(y_true, y_pred, target_names=le.classes_)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(\"\\nClassification Report:\\n\", report)\n",
    "# Expected: ML metrics and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14ead4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted topic: person\n"
     ]
    }
   ],
   "source": [
    "# step 9\n",
    "# test_texts = [\"marriag best film dream wish\"]\n",
    "test_texts = ['guess soon hair compani letter fund mission medic import tradit everyon']\n",
    "test_encodings = tokenize(test_texts)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(**{k: v for k, v in test_encodings.items()})\n",
    "    probs = torch.softmax(outputs.logits, dim=1)\n",
    "    pred_label = probs.argmax(dim=1).item()\n",
    "    pred_topic = le.inverse_transform([pred_label])[0]\n",
    "    print(\"Predicted topic:\", pred_topic)\n",
    "# Expected: Predicted topic for the input text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c101497",
   "metadata": {},
   "source": [
    "# MobileBert Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cec0dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (2.3.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (1.7.1)\n",
      "Requirement already satisfied: torch in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (2.8.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (4.56.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (1.16.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from torch) (2025.7.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (0.34.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (0.22.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from requests->transformers) (2025.7.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas scikit-learn torch transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4034d080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       question_text             topic\n",
      "0  keep somebodi maintain thing everybodi pay con...            climat\n",
      "1  audienc somebodi medic countri ball morn deter...             space\n",
      "2  person summer compani agre easi social caus ma...  entrepreneurship\n",
      "3  mention hair blue especi health compar eight r...          artifici\n",
      "4  arm success confer answer effort nation moment...          artifici\n"
     ]
    }
   ],
   "source": [
    "# step 1\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Load preprocessed CSV\n",
    "df = pd.read_csv(r\"E:\\\\Sem 7 Project\\\\Datasets\\\\Preprocessed Datasets\\\\output_part_2.csv\")\n",
    "\n",
    "# Convert list-like columns to strings if needed\n",
    "df['question_text'] = df['question_text'].apply(ast.literal_eval).apply(lambda x: ' '.join(x))\n",
    "df['topic'] = df['topic'].apply(ast.literal_eval).apply(lambda x: x[0] if len(x) > 0 else '')\n",
    "\n",
    "print(df[['question_text', 'topic']].head())\n",
    "# Expected: First 5 rows of question_text and topic columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "344c2451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               topic  label\n",
      "3           artifici      0\n",
      "22        blockchain      1\n",
      "16            career      2\n",
      "0             climat      3\n",
      "49        cybersecur      4\n",
      "81              data      5\n",
      "7              digit      6\n",
      "21              educ      7\n",
      "2   entrepreneurship      8\n",
      "51       environment      9\n",
      "9             health     10\n",
      "10           histori     11\n",
      "5             machin     12\n",
      "20            person     13\n",
      "6          psycholog     14\n",
      "26           quantum     15\n",
      "42             robot     16\n",
      "56          sociolog     17\n",
      "1              space     18\n",
      "8                web     19\n"
     ]
    }
   ],
   "source": [
    "# step 2\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['label'] = le.fit_transform(df['topic'])\n",
    "num_labels = len(le.classes_)\n",
    "print(df[['topic', 'label']].drop_duplicates().sort_values('label'))\n",
    "# Expected: Unique topics and their encoded labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0dedcbdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240 60\n"
     ]
    }
   ],
   "source": [
    "# step 3\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df['question_text'], df['label'], test_size=0.2, random_state=42, stratify=df['label']\n",
    ")\n",
    "print(len(train_texts), len(val_texts))\n",
    "# Expected: Number of training and validation samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc6204e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeysView({'input_ids': tensor([[  101,  5323,  2397,  ...,     0,     0,     0],\n",
      "        [  101,  2711,  2621,  ...,     0,     0,     0],\n",
      "        [  101,  9358,  9496,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 10346,  2319,  ...,     0,     0,     0],\n",
      "        [  101,  7487,  2128,  ...,     0,     0,     0],\n",
      "        [  101,  2028,  4929,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])})\n"
     ]
    }
   ],
   "source": [
    "# step 4\n",
    "from transformers import MobileBertTokenizer\n",
    "\n",
    "tokenizer = MobileBertTokenizer.from_pretrained('google/mobilebert-uncased')\n",
    "\n",
    "def tokenize(texts, max_length=128):\n",
    "    return tokenizer(\n",
    "        list(texts),\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "train_encodings = tokenize(train_texts)\n",
    "val_encodings = tokenize(val_texts)\n",
    "print(train_encodings.keys())\n",
    "# Expected: dict_keys(['input_ids', 'attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2324dc52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240 60\n"
     ]
    }
   ],
   "source": [
    "# step 5\n",
    "import torch\n",
    "\n",
    "class BertDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels.iloc[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = BertDataset(train_encodings, train_labels)\n",
    "val_dataset = BertDataset(val_encodings, val_labels)\n",
    "print(len(train_dataset), len(val_dataset))\n",
    "# Expected: Number of samples in train and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "459f08fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MobileBertForSequenceClassification were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\Meet\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [300/300 20:22, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4130552.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>51243.484400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>219.016600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.393600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.143400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.237400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2.857900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.934600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2.984000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.618500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2.586800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2.720200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>2.313300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2.227400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.405800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>2.076900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>2.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.958600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.772400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.676100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.705300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.387500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.476600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.432300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.255100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1.191900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1.270600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.218900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1.240400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.119600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time (seconds): 1228.76\n",
      "Training Time (minutes): 20.48\n"
     ]
    }
   ],
   "source": [
    "# step 6\n",
    "from transformers import MobileBertForSequenceClassification, Trainer, TrainingArguments\n",
    "import time\n",
    "\n",
    "model = MobileBertForSequenceClassification.from_pretrained('google/mobilebert-uncased', num_labels=num_labels)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./N-Results/results_mobilebert',\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    logging_dir='./N-Results/logs_mobilebert',\n",
    "    logging_steps=10,\n",
    "    # evaluation_strategy='epoch',\n",
    "    # save_strategy='epoch',\n",
    "    # load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "trainer.train()\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "print(f\"Training Time (seconds): {training_time:.2f}\")\n",
    "print(f\"Training Time (minutes): {training_time/60:.2f}\")\n",
    "# Expected: Training time in seconds and minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0bd192a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Meet\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.06666666666666667\n",
      "Precision: 0.08166666666666668\n",
      "Recall: 0.06666666666666667\n",
      "F1-Score: 0.06841269841269841\n",
      "Confusion Matrix:\n",
      "[[1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 2 0 1 1 0 0 0 0]\n",
      " [0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 1 0 1 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0]\n",
      " [0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "\n",
      "Classification Report:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "        artifici       0.50      0.25      0.33         4\n",
      "      blockchain       0.00      0.00      0.00         2\n",
      "          career       0.00      0.00      0.00         4\n",
      "          climat       0.00      0.00      0.00         5\n",
      "      cybersecur       0.50      0.33      0.40         3\n",
      "            data       0.00      0.00      0.00         2\n",
      "           digit       0.00      0.00      0.00         2\n",
      "            educ       0.00      0.00      0.00         3\n",
      "entrepreneurship       0.50      0.50      0.50         2\n",
      "     environment       0.00      0.00      0.00         2\n",
      "          health       0.00      0.00      0.00         3\n",
      "         histori       0.10      0.25      0.14         4\n",
      "          machin       0.00      0.00      0.00         4\n",
      "          person       0.00      0.00      0.00         3\n",
      "       psycholog       0.00      0.00      0.00         3\n",
      "         quantum       0.00      0.00      0.00         3\n",
      "           robot       0.00      0.00      0.00         2\n",
      "        sociolog       0.00      0.00      0.00         4\n",
      "           space       0.00      0.00      0.00         3\n",
      "             web       0.00      0.00      0.00         2\n",
      "\n",
      "        accuracy                           0.07        60\n",
      "       macro avg       0.08      0.07      0.07        60\n",
      "    weighted avg       0.08      0.07      0.07        60\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Meet\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\Meet\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\Meet\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# step 7\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "\n",
    "# Get predictions\n",
    "preds = trainer.predict(val_dataset)\n",
    "y_true = val_labels.values\n",
    "y_pred = preds.predictions.argmax(axis=1)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "report = classification_report(y_true, y_pred, target_names=le.classes_)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(\"\\nClassification Report:\\n\", report)\n",
    "# Expected: ML metrics and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b275531d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted topic: person\n"
     ]
    }
   ],
   "source": [
    "# step 8\n",
    "\n",
    "# test_texts = ['guess soon hair compani letter fund mission medic import tradit everyon']\n",
    "test_texts = [\"marriag best film dream wish\"]\n",
    "test_encodings = tokenize(test_texts)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(**{k: v for k, v in test_encodings.items()})\n",
    "    probs = torch.softmax(outputs.logits, dim=1)\n",
    "    pred_label = probs.argmax(dim=1).item()\n",
    "    pred_topic = le.inverse_transform([pred_label])[0]\n",
    "    print(\"Predicted topic:\", pred_topic)\n",
    "# Expected: Predicted topic for the input text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d486ac5",
   "metadata": {},
   "source": [
    "# Electra Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "91573a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (2.3.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (1.7.1)\n",
      "Requirement already satisfied: torch in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (2.8.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (4.56.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (1.16.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from torch) (2025.7.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (0.34.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (0.22.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\meet\\appdata\\roaming\\python\\python313\\site-packages (from requests->transformers) (2025.7.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas scikit-learn torch transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cce89dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       question_text      topic\n",
      "0  organ choos concern eye stage three point desp...    quantum\n",
      "1  certainli turn marriag consid environ school p...     climat\n",
      "2                       marriag best film dream wish  psycholog\n",
      "3  guess soon hair compani letter fund mission me...    histori\n",
      "4  know say congress view wear amount money succe...     machin\n"
     ]
    }
   ],
   "source": [
    "# step 1\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Load your preprocessed CSV\n",
    "df = pd.read_csv(r\"E:\\\\Sem 7 Project\\\\Datasets\\\\Preprocessed Datasets\\\\output_part_1.csv\")  # Change path if needed\n",
    "\n",
    "# Convert list-like columns to strings if needed\n",
    "if isinstance(df['question_text'].iloc[0], str) and df['question_text'].iloc[0].startswith(\"[\"):\n",
    "    df['question_text'] = df['question_text'].apply(ast.literal_eval).apply(lambda x: ' '.join(x))\n",
    "if isinstance(df['topic'].iloc[0], str) and df['topic'].iloc[0].startswith(\"[\"):\n",
    "    df['topic'] = df['topic'].apply(ast.literal_eval).apply(lambda x: x[0] if len(x) > 0 else '')\n",
    "\n",
    "print(df[['question_text', 'topic']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d36be4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               topic  label\n",
      "6           artifici      0\n",
      "28        blockchain      1\n",
      "10            career      2\n",
      "1             climat      3\n",
      "5         cybersecur      4\n",
      "39              data      5\n",
      "17             digit      6\n",
      "9               educ      7\n",
      "22  entrepreneurship      8\n",
      "7        environment      9\n",
      "69            health     10\n",
      "3            histori     11\n",
      "4             machin     12\n",
      "31            person     13\n",
      "2          psycholog     14\n",
      "0            quantum     15\n",
      "20             robot     16\n",
      "18          sociolog     17\n",
      "8              space     18\n",
      "14               web     19\n"
     ]
    }
   ],
   "source": [
    "# step 2\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['label'] = le.fit_transform(df['topic'])\n",
    "num_labels = len(le.classes_)\n",
    "print(df[['topic', 'label']].drop_duplicates().sort_values('label'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1dfae68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160 40\n"
     ]
    }
   ],
   "source": [
    "# step 3\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df['question_text'], df['label'], test_size=0.2, random_state=42, stratify=df['label']\n",
    ")\n",
    "print(len(train_texts), len(val_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74e150fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 4\n",
    "from transformers import ElectraTokenizer\n",
    "\n",
    "tokenizer = ElectraTokenizer.from_pretrained('google/electra-base-discriminator')\n",
    "\n",
    "def tokenize(texts, max_length=128):\n",
    "    return tokenizer(\n",
    "        list(texts),\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "train_encodings = tokenize(train_texts)\n",
    "val_encodings = tokenize(val_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad6222de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 5\n",
    "import torch\n",
    "\n",
    "class ElectraDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels.iloc[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = ElectraDataset(train_encodings, train_labels)\n",
    "val_dataset = ElectraDataset(val_encodings, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4611265",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-base-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\Meet\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 45:13, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.010200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.024300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.986800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.006500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.974100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2.981000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.988200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2.958300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.984200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2.957300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2.976700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>2.946400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2.979500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>2.986800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>2.946500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>2.955700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>2.952300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.930100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=200, training_loss=2.97373685836792, metrics={'train_runtime': 2726.8904, 'train_samples_per_second': 0.587, 'train_steps_per_second': 0.073, 'total_flos': 105261431193600.0, 'train_loss': 2.97373685836792, 'epoch': 10.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 6\n",
    "from transformers import ElectraForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "model = ElectraForSequenceClassification.from_pretrained('google/electra-base-discriminator', num_labels=num_labels)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./N-Results/electra',\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    logging_dir='./N-Results/logs',\n",
    "    logging_steps=10,\n",
    "    # evaluation_strategy='epoch',\n",
    "    # save_strategy='epoch',\n",
    "    # load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "319f5d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Meet\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.125\n",
      "Precision: 0.060555555555555564\n",
      "Recall: 0.125\n",
      "F1-Score: 0.0725\n",
      "\n",
      "Classification Report:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "        artifici       0.40      0.67      0.50         3\n",
      "      blockchain       0.00      0.00      0.00         3\n",
      "          career       0.50      0.50      0.50         2\n",
      "          climat       0.00      0.00      0.00         2\n",
      "      cybersecur       0.00      0.00      0.00         2\n",
      "            data       0.00      0.00      0.00         3\n",
      "           digit       0.00      0.00      0.00         3\n",
      "            educ       0.00      0.00      0.00         1\n",
      "entrepreneurship       0.00      0.00      0.00         2\n",
      "     environment       0.00      0.00      0.00         2\n",
      "          health       0.00      0.00      0.00         1\n",
      "         histori       0.00      0.00      0.00         1\n",
      "          machin       0.00      0.00      0.00         1\n",
      "          person       0.07      0.67      0.13         3\n",
      "       psycholog       0.00      0.00      0.00         2\n",
      "         quantum       0.00      0.00      0.00         1\n",
      "           robot       0.00      0.00      0.00         3\n",
      "        sociolog       0.00      0.00      0.00         2\n",
      "           space       0.00      0.00      0.00         2\n",
      "             web       0.00      0.00      0.00         1\n",
      "\n",
      "        accuracy                           0.12        40\n",
      "       macro avg       0.05      0.09      0.06        40\n",
      "    weighted avg       0.06      0.12      0.07        40\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Meet\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\Meet\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\Meet\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# step 7\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "\n",
    "# Get predictions\n",
    "preds = trainer.predict(val_dataset)\n",
    "y_true = val_labels.values\n",
    "y_pred = preds.predictions.argmax(axis=1)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b4bf2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted topic: career\n"
     ]
    }
   ],
   "source": [
    "test_texts = [\"marriag best film dream wish\"]  # Example test text\n",
    "test_encodings = tokenize(test_texts)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(**{k: v for k, v in test_encodings.items()})\n",
    "    probs = torch.softmax(outputs.logits, dim=1)\n",
    "    pred_label = probs.argmax(dim=1).item()\n",
    "    pred_topic = le.inverse_transform([pred_label])[0]\n",
    "    print(\"Predicted topic:\", pred_topic)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
